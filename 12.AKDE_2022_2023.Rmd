---
title: "AKDE_2022_2023"
author: "Camila Calderon"
date: "2024-09-30"
output: html_document
---

#Loading packages

```{r setup, include=FALSE}
library(ctmm)
library(ggplot2)
library(tidyverse)
library(lubridate)
library(doBy)
library(gganimate)
library(ggmap)
library(spatialrisk)
library(plotly)
```

## Loading files

```{r load, results="hide", include=TRUE}
####### Load foraging data with filtered dates #####
load(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/bocas_2022-2023HMMbehaviors.RData")

unique(bocas$cave)

### FORAGING ###
#adding counts to each consecutive point of foraging and commuting
bocas$n <- NA

r <- rle(bocas$behav)

for(i in 1:length(r$lengths)){
  #if(r$values[i] == "commuting"){
  start <- {}
  end <- {}
  try(start <- sum(r$lengths[1:(i-1)])+1)
  if(i == 1) start <- 1
  end <- sum(r$lengths[1:i])
  
  bocas$n[start:end] <- r$lengths[i]
}


bocas$behav[bocas$event_id=="1592348772"] <- "commuting"

#select foraging points from 2022 and wet season 2023
bats_foraging <- bocas %>%
  filter(behav=="foraging"& n>=4)

#mapview::mapView(bats_foraging, xcol="location_long", ycol="location_lat", zcol="tag_local_identifier", legend=F, crs="EPSG:4326")

```

## Removing foraging points inside Isla Col√≥n

```{r pressure, results="hide", message=FALSE, warning=FALSE}
###### Removing foraging points on the island with a big radios ######

# Set coordinates of middle of the roost
roostlagruta <- data.frame(location.lat=9.396448, location.long=-82.271541)
roostsena <- data.frame(location.lat=9.059652, location.long=-79.65391)

# selecting foraging points based on the radious by taking la gruta as a reference point
roostpointGruta <- points_in_circle(bats_foraging, roostlagruta$location.long,roostlagruta$location.lat, radius = 6500, lon=location_long,lat=location_lat)

roostpointSENA <- points_in_circle(bats_foraging, roostsena$location.long,roostsena$location.lat, radius = 500, lon=location_long,lat=location_lat)

# remove foraging points from island and house the data frame
foragingall_noisla <- bats_foraging[!(bats_foraging$event_id %in% roostpointGruta$event_id),] 

foragingall_noisla <- foragingall_noisla[!(foragingall_noisla$event_id %in% roostpointSENA$event_id),] 

# plot with no foraging point on the island
plot(foragingall_noisla$location_long, foragingall_noisla$location_lat)

#check unique IDs
unique(foragingall_noisla$date)

foragingall_noisla$season <- "dry"
foragingall_noisla$season[which(foragingall_noisla$cave_year=="lagruta2023" )] <- "wet"

# I remove id_day with less than 10 points

# create a list
bats.cave_ls <- split(foragingall_noisla, foragingall_noisla$ID)

# filter to have only id_days with more than 10 points
bats.cave_ls <- Filter(function(bats.cave_ls) nrow(bats.cave_ls) > 10, bats.cave_ls)

# convert to data frame again
bats.cave_clean <- do.call(rbind, bats.cave_ls)

# save
save(bats.cave_clean, file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/bocas_foragingnoisland.RData")

# plot foraging points of filtered data frame
mapview::mapView(bats.cave_clean, xcol="location_long", ycol="location_lat", zcol="tag_local_identifier", legend=F, crs="EPSG:4326")

# save foraging points
save(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/bocas_gamboa_foragingpoints.RData")
```

## Convert to telemetry object

```{r convert to telemetry}
#data frame with only tracking from February
bats_feb <- bats.cave_clean %>% 
 filter(date> "2022-01-01" & date < "2022-03-01", tag_local_identifier!="0C506E35_G")
#names(bats_feb)

#plot
# mapview::mapView(bats_feb, xcol="location_long", ycol="location_lat", zcol="tag_local_identifier", legend=F, crs="EPSG:4326")

#remove columns names to so that it takes IDdate as a id in the telemetry object
bats_feb_idday <- bats_feb[,c(-22,-23,-28,-30,-33,-40,-41,-43,-51,-61)]#,-46

save(bats_feb_idday, file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper2/analysis/data/bats_feb_idday.RData")

#convert to telemetry object
tele.idday.feb <- as.telemetry(bats_feb_idday)
tele.idday.feb[[1]]@info$projection
```

### UDs per idday

```{r}
library(doParallel)
library(foreach)
#calculating fits for each individual day
uere(tele.idday.feb) <- 20

# include two-point equidistant projection
ctmm::projection(tele.idday.feb) <- median(tele.idday.feb, k=2)

## backend for foreach (this works for Windows, when running on MAC you may have to use another backend method):
cl <- parallel::makeCluster(detectCores(), outfile = "")
doParallel::registerDoParallel(cl)

# create a 'fitting' function
fitting_function <- function(i){
  T.GUESS <- ctmm.guess(tele.idday.feb[[i]], CTMM = ctmm(error = T), interactive=F)
  ctmm.select(tele.idday.feb[[i]], T.GUESS, verbose = T, trace=2)
}

# use the fitting function in a foreach loop and parrallel backend by using %dopar%
FITS_2022 <- foreach(i=1: length(tele.idday.feb), .packages='ctmm') %dopar% { fitting_function(i) }

parallel::stopCluster(cl)

# ###
# FITS_idday <- lapply(tele.idday.feb, function(x){
#   print(x)
#   SVF <- variogram(x)#dt = c(2, 1440 %#% "minutes")
#   GUESS <- ctmm.guess(x, CTMM=ctmm(error=TRUE), interactive=FALSE)#CTMM=ctmm(error=TRUE)
#   FITS_idday <- ctmm.select(x,GUESS,trace=3, cores=2, verbose=T)
#   return(FITS_idday)
# })

# 
names(FITS_2022) <- names(tele.idday.feb)
# check for projection
projection(FITS_2022) 

# #save fits without grid
save(FITS_2022,file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/fits_2022_20240918.RData")#this fits works
load(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/fits_idday_Feb_20240930.RData")

#calculate AKDE 
future::availableCores() 
options(mc.cores = parallel::detectCores()) 

#####  if we use a grid, we can use this part #####
# ex <- extent(tele.idday.feb)
# ex$x <- round(ex$x/500 + c(-10,10))*500
# ex$y <- round(ex$y/500 + c(-10,10))*500
# 
# proj.all <- tele.idday.feb[[1]]@info$projection
# grid <- list(dr=c(500,500), extent=raster:::extent(ex$x, ex$y))

# calculate AKDE without grid
UDS_idday <- lapply(1:length(tele.idday.feb), function(i){
  idday <- names(tele.idday.feb[i])
  print(idday)
  # Ensure tele.2016[[i]] instead of tele.2016[[idday]], unless idday is exactly the index name
  akde_result <- tryCatch({
    akde(tele.idday.feb[[i]], FITS_2022[[idday]], weights=TRUE,grid=list(dr=500, align.to.origin=T))#list(dr=500, align.to.origin=T)
  }, error = function(e) {
    cat("Error in processing idday", idday, ": ", e$message, "\n")
    return(NULL) # Returning NULL or any other indication of the error
  })
  return(akde_result)
})

#add names to list
names(UDS_idday) <- names(tele.idday.feb)

#plot ud
plotUDS_idday <- lapply(1:length(UDS_idday), function(i) {
  id <- names(UDS_idday[i])
  print(id)  # This will print the current id being processed
  
  # Attempt to plot, handle cases where id is not found or other errors occur
  tryCatch({
    # Check if id exists in UDS_idday
    if(is.null(UDS_idday[[id]])) {
      cat("ID", id, "not found in UDS_idday.\n")
    } else {
      # If id exists, plot the data
      ctmm::plot(tele.idday.feb[[id]], UD=UDS_idday[[id]])
    }
  }, error = function(e) {
    # This will execute if there is an error in the plotting process
    cat("Error while plotting ID", id, ":", e$message, "\n")
  })
})


## save UDs
save(UDS_idday,file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/udsgrid_idday_Feb_20240807.RData")
load(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/udsgrid_idday_Feb_20240807.RData")
```


## OVERLAP DEFINITION

This function calculates a useful measure of similarity between distributions known as the Bhattacharyya coefficient in statistics and simply the fidelity or overlap in quantum and statistical mechanics. It is roughly speaking the ratio of the intersection area to the average individual area, but it is a direct comparison between the density functions and does not require an arbitrary quantile to be specified. When applied to ctmm objects, this function returns the overlap of the two Gaussian distributions. When applied to aligned UD objects with corresponding movement models, this function returns the overlap of their (autocorrelated) kernel density estimates.

Overlap by individual day

```{r}
#remove null objects from a list
UDS_idday_filtered <- Filter(Negate(is.null), UDS_idday)

BA_ud_idday_95 <- ctmm::overlap(UDS_idday_filtered, level=.95) 
# BA_ud_idday_50 <- overlap(UDS_idday_filtered, level=.50) 
# BA_ud_idday_20 <- overlap(UDS_idday_filtered, level=.20) 


#convert to data frame
library(reshape2)
BA_ud_idday_95_df <- melt(BA_ud_idday_95$CI[,,"est"])
#remove comparison between same ID
BA_ud_idday_95_df <- BA_ud_idday_95_df[BA_ud_idday_95_df$Var1!=BA_ud_idday_95_df$Var2,]
#remove duplicates
BA_ud_idday_95_df <- BA_ud_idday_95_df[duplicated(BA_ud_idday_95_df$value),]
#add group and id to the table
BA_ud_idday_95_df <- BA_ud_idday_95_df %>%
   mutate(id1 = str_sub(Var1, 1,10),id2 = str_sub(Var2, 1,10),
         date1=str_sub(Var1,12), date2=str_sub(Var2,12))#group1 = str_sub(Var1,10,10), group2 = str_sub(Var2,10,10), groups=paste(group1,group2, sep="_")
#change groups
#BA_ud_idday_95_df$groups[which(BA_ud_idday_95_df$groups=="D_G")] <- "G_D"

#verify groups
# unique(BA_ud_idday_95_df$groups)

#add columns
BA_ud_idday_95_df$samedate <- ifelse(BA_ud_idday_95_df$date1==BA_ud_idday_95_df$date2, "yes","no")
BA_ud_idday_95_df$sameid <- ifelse(BA_ud_idday_95_df$id1==BA_ud_idday_95_df$id2, "yes","no")
BA_ud_idday_95_df$period <- "dry 2022-1"

#using same date
# overlap_sameid95 <- BA_ud_idday_95_df[BA_ud_idday_95_df$id1==BA_ud_idday_95_df$id2,]
# overlap_sameid95$groups[which(overlap_sameid95$groups=="D_D")] <- "D_D_id"
# overlap_sameid95$groups[which(overlap_sameid95$groups=="G_G")] <- "G_G_id"
# overlap_sameid95$sameid <- ifelse(overlap_sameid95$id1==overlap_sameid95$id2, "yes","no")
# overlap_sameid95$cave <- "lagruta_2022"

#plot overlap within and between individuals including same and different days
over_within <- ggplot(aes(x= sameid,y=value, fill = sameid), data=BA_ud_idday_95_df) +
 geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values = c("black", "grey"))+
  #geom_point(position = position_jitter(seed = 1, width = 0.2)) +
stat_summary(fun = mean, color = "red") +
  stat_summary(
    fun.min = function(x) mean(x) - sd(x), 
    fun.max = function(x) mean(x) + sd(x), 
    geom = "errorbar",
    color = "red",
    width = .3
  )+
  theme_classic()
over_within 
ggsave(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/analysis/results/akde/overlap_withinid_feb.pdf")

# #remove same id but compare same days and groups
# overlap_idday95 <- BA_ud_idday_95_df[BA_ud_idday_95_df$date1==BA_ud_idday_95_df$date2,]
# overlap_idday95 <- overlap_idday95[overlap_idday95$groups!="G_D",]
# 
# #plot overlap between individuals from the same and different groups
# over_between <- ggplot(aes(x=groups, y=value), data=overlap_idday95) +
#   geom_boxplot()+
#   geom_jitter()+
# stat_summary(fun = mean, color = "red") +
#   stat_summary(
#     fun.min = function(x) mean(x) - sd(x), 
#     fun.max = function(x) mean(x) + sd(x), 
#     geom = "errorbar",
#     color = "red",
#     width = .3
#   )
# over_between 
# ggsave(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/analysis/results/akde/overlap_iddaygroups_feb.pdf")
# 
# #join plot
# library(patchwork)
# over_within / over_between
# 
# ggsave(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/analysis/results/akde/overlap_withinbetween_feb.pdf")
```

### Check data after march before calculating areas

```{r}
aftermarch <- bocas %>%
  filter(date > "2022-03-01" )

lapply(split(aftermarch, aftermarch$tag_local_identifier), function(x){
  ggplot(x, aes(x=location_long, y=location_lat, color=as.factor(date)))+geom_point()+
    ggtitle(x$tag_local_identifier)
})
```
### Selecting foraging points for 2022 and 2023

```{r tracking data from 2022 and 2023}
#foraging points of march
bats_2022_2023 <- bats.cave_clean%>%
  group_by(ID_batday)%>%
 filter(date>="2022-03-01")

# look at foraging points before removing points which look like outliers
lapply(split(bats_2022_2023, bats_2022_2023$tag_local_identifier), function(x){
  ggplot(x, aes(x=location_long, y=location_lat, color=ground_speed))+geom_point()+
    ggtitle(x$tag_local_identifier)
})

bats_2022_2023_ls <- split(bats_2022_2023, bats_2022_2023$tag_local_identifier) 

mapview::mapView(bats_2022_2023_ls[[1]], xcol="location_long", ycol="location_lat", zcol="tag_local_identifier", legend=F, crs="EPSG:4326")

bats_2022_2023_c <- bats_2022_2023[!c(bats_2022_2023$event_id=="22068513105"| bats_2022_2023$event_id=="22068505851" | bats_2022_2023$event_id=="22068511044" | bats_2022_2023$event_id=="22068513168" | bats_2022_2023$event_id=="22068507462" | bats_2022_2023$event_id=="22068508865" | bats_2022_2023$event_id=="22068506967" |  bats_2022_2023$event_id=="22068503302" | bats_2022_2023$event_id=="22068503294" | bats_2022_2023$event_id=="22068505156" | bats_2022_2023$event_id=="22068512087" | bats_2022_2023$event_id=="22068509285" | bats_2022_2023$event_id=="22068516108" | bats_2022_2023$event_id=="22068510603" | bats_2022_2023$event_id=="22068507793" | bats_2022_2023$event_id=="22068511262" | bats_2022_2023$event_id=="22068506164" | bats_2022_2023$event_id=="22068508800" | bats_2022_2023$event_id=="29640586058" | bats_2022_2023$event_id=="29640586061" | bats_2022_2023$event_id=="29640586063" | bats_2022_2023$event_id=="29640588927" | bats_2022_2023$event_id=="29640511851" | bats_2022_2023$event_id=="29640511921" | bats_2022_2023$event_id=="29640513359" | bats_2022_2023$event_id=="29640499165" | bats_2022_2023$event_id=="29640498290"),]


# remove bats with only one day of tracking
bats_2022_2023_c <- bats_2022_2023_c[!c(bats_2022_2023_c$tag_local_identifier=="PH_TS_004"| bats_2022_2023_c$tag_local_identifier=="PH_TS_024" | bats_2022_2023_c$tag_local_identifier=="PHYL34" | bats_2022_2023_c$tag_local_identifier=="PHYL4"),]

# look at foraging points before removing points which look like outliers
lapply(split(bats_2022_2023_c, bats_2022_2023_c$tag_local_identifier), function(x){
  ggplot(x, aes(x=location_long, y=location_lat, color=as.factor(date)))+geom_point()+
    ggtitle(x$tag_local_identifier)
})
```
### Convert to telemetry object data from 2022

```{r}
### only 202 data
idday2022 <- bats_2022_2023_c[,c(-23,-24,-28,-30,-33,-41,-43,-53,-61)]%>%
  filter(date<="2023-01-01")

#convert to telemetry object
tele2022<- as.telemetry(idday2022)
tele2022[[1]]@info$projection

plot(tele2022)
```

### Convert to telemetry object data from 2023
```{r}
bats2023 <- bats_2022_2023_c[,c(-23,-24,-28,-30,-33,-41,-43,-53,-61)] %>%
  filter(date>="2023-01-01")

#convert to telemetry object
tele2023<- as.telemetry(bats2023)
bats2023[[1]]@info$projection

plot(tele2023)

```
### Calculate fits for 2022 data

```{r}
#error
uere(tele2022) <- 20

# include two-point equidistant projection
ctmm::projection(tele2022) <- median(tele2022, k=2)

## backend for foreach (this works for Windows, when running on MAC you may have to use another backend method):
cl <- parallel::makeCluster(detectCores(), outfile = "")
doParallel::registerDoParallel(cl)

# create a 'fitting' function
fit_function <- function(i){
  T.GUESS <- ctmm.guess(tele2022[[i]], CTMM = ctmm(error = T), interactive=F)
  ctmm.select(tele2022[[i]], T.GUESS, verbose = T, trace=2)
}

# use the fitting function in a foreach loop and parrallel backend by using %dopar%
FITS_2022 <- foreach(i=1: length(tele2022), .packages='ctmm') %dopar% { fitting_function(i) }

parallel::stopCluster(cl)

# 
names(FITS_2022) <- names(tele2022)
# check for projection
projection(FITS_2022) 

# #save fits without grid
save(FITS_2022,file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/fits_2022_20240918.RData")#this fits works
load(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/fits_2022_20240918.RData")

load(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/fits_2022-3_20240912.RData")
```

### calculate UDs for individuals in march 2022 
```{r}
# calculate AKDE with grid
UDS_2022 <- lapply(1:length(tele2022), function(i){
  idday <- names(tele2022[i])
  print(idday)
  # Ensure tele.2016[[i]] instead of tele.2016[[idday]], unless idday is exactly the index name
  akde_result <- tryCatch({
    akde(tele2022[[i]], FITS_2022[[idday]]$`OUf error`, weights=TRUE, grid=list(dr=500, align.to.origin=T))#list(dr=500, align.to.origin=T)
  }, error = function(e) {
    cat("Error in processing idday", idday, ": ", e$message, "\n")
    return(NULL) # Returning NULL or any other indication of the error
  })
  return(akde_result)
})

#add names to list
names(UDS_2022) <- names(tele2022)

plot(UDS_2022[[6]], FITS_2022[[6]])

## save UDs
save(UDS_2022,file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/udsgrid2022_20240923.RData")

```

### Calculate fits for individuals in August 2023

```{r}
uere(tele2023) <- 20

# include two-point equidistant projection
ctmm::projection(tele2023) <- median(tele2023, k=2)

## backend for foreach (this works for Windows, when running on MAC you may have to use another backend method):
cl <- parallel::makeCluster(detectCores(), outfile = "")
doParallel::registerDoParallel(cl)

# create a 'fitting' function
fit_function2023 <- function(i){
  T.GUESS <- ctmm.guess(tele2023[[i]], CTMM = ctmm(error = T), interactive=F)
  ctmm.select(tele2023[[i]], T.GUESS, verbose = T, trace=2)
}

# use the fitting function in a foreach loop and parrallel backend by using %dopar%
FITS_2023 <- foreach(i=1: length(tele2023), .packages='ctmm') %dopar% { fit_function2023(i) }

parallel::stopCluster(cl)

# 
names(FITS_2023) <- names(tele2023)
# check for projection
projection(FITS_2023) 

save(FITS_2023, file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/fits_2023_20240923.RData")
load(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/fits_2023_20240923.RData")
```
### Calculate UDs for individuals in August 2023
```{r}
# calculate AKDE with grid
UDS_2023 <- lapply(1:length(tele2023), function(i){
  idday <- names(tele2023[i])
  print(idday)
  # Ensure tele.2016[[i]] instead of tele.2016[[idday]], unless idday is exactly the index name
  akde_result <- tryCatch({
    akde(tele2023[[i]], FITS_2023[[idday]]$`OUf error`, weights=TRUE, grid=list(dr=500, align.to.origin=T))#list(dr=500, align.to.origin=T)
  }, error = function(e) {
    cat("Error in processing idday", idday, ": ", e$message, "\n")
    return(NULL) # Returning NULL or any other indication of the error
  })
  return(akde_result)
})

#add names to list
names(UDS_2023) <- names(tele2023)

## save UDs
save(UDS_2023,file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/data/udsgrid2023_20240923.RData")
```

### Calculate overlap for 2022 march

```{r}
#remove null objects from a list
UDS_2022_filtered <- Filter(Negate(is.null), UDS_2022)
UDS_2022_filtered <- UDS_2022_filtered[sapply(UDS_2022_filtered, function(x) inherits(x, "UD"))]

# UDS_2022_filtered <- UDS_2022_filtered[c(-54)]

# leave only individuasl drom the aj cave
UDS_2022_filtered <- UDS_2022_filtered[names(UDS_2022_filtered) %in%  c("PH_TS_011_2022-03-07", "PH_TS_011_2022-03-08", "PH_TS_011_2022-03-09", "PH_TS_011_2022-03-10", "PH_TS_011_2022-03-11", "PH_TS_011_2022-03-12", "PH_TS_011_2022-03-13", "PH_TS_011_2022-03-14", "PH_TS_011_2022-03-15", "PH_TS_011_2022-03-16", "PH_TS_011_2022-03-17", "PH_TS_014_2022-03-07", "PH_TS_014_2022-03-08", "PH_TS_014_2022-03-09", "PH_TS_014_2022-03-10", "PH_TS_014_2022-03-11", "PH_TS_014_2022-03-12", "PH_TS_014_2022-03-13", "PH_TS_014_2022-03-14", "PH_TS_016_2022-03-09", "PH_TS_016_2022-03-10", "PH_TS_074_2022-03-08", "PH_TS_074_2022-03-09", "PH_TS_074_2022-03-10", "PH_TS_074_2022-03-11", "PH_TS_074_2022-03-12", "PH_TS_016_2022-03-11", "PH_TS_016_2022-03-16", "PH_TS_016_2022-03-17",  "PH_TS_079_2022-03-10", "PH_TS_079_2022-03-11", "PH_TS_079_2022-03-12", "PH_TS_079_2022-03-13", "PH_TS_079_2022-03-14", "PH_TS_079_2022-03-15", "PH_TS_079_2022-03-18", "PH_TS_080_2022-03-08", "PH_TS_080_2022-03-09", "PH_TS_080_2022-03-10", "PH_TS_080_2022-03-11", "PH_TS_080_2022-03-12", "PH_TS_080_2022-03-14", "PH_TS_080_2022-03-16", "PH_TS_080_2022-03-17", "PH_TS_080_2022-03-19", "PH_TS_080_2022-03-20", "PH_TS_080_2022-03-21", "PH_TS_083_2022-03-08", "PH_TS_083_2022-03-09", "PH_TS_083_2022-03-10", "PH_TS_083_2022-03-11", "PH_TS_083_2022-03-13", "PH_TS_098_2022-03-07", "PH_TS_098_2022-03-08", "PH_TS_098_2022-03-09", "PH_TS_112_2022-03-09", "PH_TS_112_2022-03-11",  "PH_TS_112_2022-03-12", "PH_TS_113_2022-03-08", "PH_TS_113_2022-03-10", "PH_TS_113_2022-03-12", "PH_TS_120_2022-03-08", "PH_TS_120_2022-03-09", "PH_TS_121_2022-03-08", "PH_TS_121_2022-03-10", "PH_TS_121_2022-03-11", "PH_TS_121_2022-03-14") == TRUE] #individual 100 does not calculate good AKDE


BA_ud_2022_95 <- ctmm::overlap(UDS_2022_filtered, level=.95) 

#convert to data frame
library(reshape2)
BA_ud_2022_95_df <- melt(BA_ud_2022_95$CI[,,"est"])
#remove comparison between same ID
BA_ud_2022_95_df <- BA_ud_2022_95_df[BA_ud_2022_95_df$Var1!=BA_ud_2022_95_df$Var2,]
#remove duplicates
BA_ud_2022_95_df <- BA_ud_2022_95_df[duplicated(BA_ud_2022_95_df$value),]
#add group and id to the table
BA_ud_2022_95_df <- BA_ud_2022_95_df %>%
   mutate(id1 = str_sub(Var1, end=-12),id2 = str_sub(Var2, end=-12),
         date1=str_sub(Var1,-10), date2=str_sub(Var2,-10))

BA_ud_2022_95_df$sameid <- ifelse(BA_ud_2022_95_df$id1==BA_ud_2022_95_df$id2, "yes", "no")
BA_ud_2022_95_df$samedate <- ifelse(BA_ud_2022_95_df$date1==BA_ud_2022_95_df$date2, "yes", "no")
BA_ud_2022_95_df$period <- "dry 2022-2"

#plot overlap within  and between individuals
within_between_2022 <- ggplot(aes(x=sameid, y=value, color=sameid), data=BA_ud_2022_95_df) +
   geom_jitter(aes(color=sameid, alpha=0.5), position = position_jitter(0.2)) + 
stat_summary(fun = mean, color = "black") +
  stat_summary(
    fun.min = function(x) mean(x) - sd(x), 
    fun.max = function(x) mean(x) + sd(x), 
    geom = "errorbar",
    color = "black",
    width = .3
  )
  #geom_pointrange()
within_between_2022 

# #using same date
# overlap_sameid95_2022 <- BA_ud_2022_95_df[BA_ud_2022_95_df$id1==BA_ud_2022_95_df$id2,]
# overlap_sameid95_2022$sameid <- ifelse(overlap_sameid95_2022$id1==overlap_sameid95_2022$id2, "yes", "no")
# 
# #plot overlap within individuals
# over_within_2022 <- ggplot(aes(x=sameid, y=value), data=overlap_sameid95_2022) +
#   geom_boxplot()+
#   geom_jitter()+
# stat_summary(fun = mean, color = "red") +
#   stat_summary(
#     fun.min = function(x) mean(x) - sd(x), 
#     fun.max = function(x) mean(x) + sd(x), 
#     geom = "errorbar",
#     color = "red",
#     width = .3
#   )
# over_within_2022 
# ggsave(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/analysis/results/akde/overlap_withinid_feb.pdf")
# 
# #remove same id but compare same days and groups
# overlap_idday95_2022 <- BA_ud_2022_95_df[BA_ud_2022_95_df$date1==BA_ud_2022_95_df$date2,]
# overlap_idday95_2022$sameid <- ifelse(overlap_idday95_2022$id1==overlap_idday95_2022$id2, "yes", "no")
# 
# #plot overlap between individuals from the same and different groups
# over_between_2022 <- ggplot(aes(x=sameid, y=value), data=overlap_idday95_2022) +
#   #geom_boxplot()+
#   geom_jitter()+
# stat_summary(fun = mean, color = "red") +
#   stat_summary(
#     fun.min = function(x) mean(x) - sd(x), 
#     fun.max = function(x) mean(x) + sd(x), 
#     geom = "errorbar",
#     color = "red",
#     width = .3
#   )
# over_between_2022
```

### Calculate overlap for August 2023

```{r}
#remove null objects from a list
UDS_2023_filtered <- Filter(Negate(is.null), UDS_2023)
UDS_2023_filtered <- UDS_2023_filtered[sapply(UDS_2023_filtered, function(x) inherits(x, "UD"))]

#removes ID with only one day
#UDS_2023_filtered <- UDS_2023_filtered[c(-15, -16,-20)]

UDS_2023_filtered <- UDS_2023_filtered[names(UDS_2023_filtered)%in% c("PHYL1_2023-08-15","PHYL1_2023-08-17","PHYL38_2023-08-12","PHYL38_2023-08-14", "PHYL39_2023-08-13" , "PHYL39_2023-08-14")==FALSE] 

BA_ud_2023_95 <- ctmm::overlap(UDS_2023_filtered, level=.95) 

#convert to data frame
BA_ud_2023_95_df <- melt(BA_ud_2023_95$CI[,,"est"])
#remove comparison between same ID
BA_ud_2023_95_df <- BA_ud_2023_95_df[BA_ud_2023_95_df$Var1!=BA_ud_2023_95_df$Var2,]
#remove duplicates
BA_ud_2023_95_df <- BA_ud_2023_95_df[duplicated(BA_ud_2023_95_df$value),]
#add group and id to the table
BA_ud_2023_95_df <- BA_ud_2023_95_df %>%
   mutate(id1 = str_sub(Var1, end=-12),id2 = str_sub(Var2, end=-12),
         date1=str_sub(Var1,-10), date2=str_sub(Var2,-10))

BA_ud_2023_95_df$sameid <- ifelse(BA_ud_2023_95_df$id1==BA_ud_2023_95_df$id2, "yes", "no")
BA_ud_2023_95_df$samedate <- ifelse(BA_ud_2023_95_df$date1==BA_ud_2023_95_df$date2, "yes", "no")
BA_ud_2023_95_df$period <- "wet 2023"

#plot overlap within  and between individuals
within_between_2023 <- ggplot(aes(x=sameid, y=value), data=BA_ud_2023_95_df) +
  geom_boxplot()+
  geom_jitter()+
stat_summary(fun = mean, color = "red") +
  stat_summary(
    fun.min = function(x) mean(x) - sd(x), 
    fun.max = function(x) mean(x) + sd(x), 
    geom = "errorbar",
    color = "red",
    width = .3
  )
within_between_2023

#using same date
# overlap_sameid95_2023 <- BA_ud_2023_95_df[BA_ud_2023_95_df$id1==BA_ud_2023_95_df$id2,]
# overlap_sameid95_2023$sameid <- ifelse(overlap_sameid95_2023$id1==overlap_sameid95_2023$id2, "yes", "no")

#plot overlap within individuals
# over_within_2023 <- ggplot(aes(x=sameid, y=value), data=overlap_sameid95_2023) +
#   geom_boxplot()+
#   geom_jitter()+
# stat_summary(fun = mean, color = "red") +
#   stat_summary(
#     fun.min = function(x) mean(x) - sd(x), 
#     fun.max = function(x) mean(x) + sd(x), 
#     geom = "errorbar",
#     color = "red",
#     width = .3
#   )
# over_within_2023
# ggsave(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/analysis/results/akde/overlap_withinid_feb.pdf")

#remove same id but compare same days and groups
# overlap_idday95_2023 <- BA_ud_2023_95_df[BA_ud_2023_95_df$date1==BA_ud_2023_95_df$date2,]
# overlap_idday95_2023$sameid <- ifelse(overlap_idday95_2023$id1==overlap_idday95_2023$id2, "yes", "no")
# 
# #plot overlap between individuals from the same and different groups
# over_between_2023 <- ggplot(aes(x=sameid, y=value), data=overlap_idday95_2023) +
#   #geom_boxplot()+
#   geom_jitter()+
# stat_summary(fun = mean, color = "red") +
#   stat_summary(
#     fun.min = function(x) mean(x) - sd(x), 
#     fun.max = function(x) mean(x) + sd(x), 
#     geom = "errorbar",
#     color = "red",
#     width = .3
#   )
# over_between_2023
```

### Make plot and test overlap
```{r}
#join dataframes
overlap_all <- rbind(BA_ud_idday_95_df, BA_ud_2022_95_df, BA_ud_2023_95_df)
overlap_all$sameid <- factor(overlap_all$sameid, levels=c("yes","no"))

## overlap with only pairwise comparison between individuals in the same dates
overlap_all_sub <- overlap_all%>%
  filter(sameid!="no"| samedate!="no")

library(ggh4x)# for dinamic color in facewraps

# Only colour strips in x-direction
strip <- strip_themed(background_x = elem_list_rect(fill = c("#756BB1", "#21918c","#F0E442"), alpha=c(0.5)))
# Necessary to put RH% into the facet labels
period_names <- as_labeller(
     c(`dry 2022-1` = "Dry 2022-1", `dry 2022-2` = "Dry 2022-2",`wet 2023` = "Wet 2023"))

#make plot
within_between_all <- ggplot(aes(x=sameid, color=sameid, group=sameid), data=overlap_all) +
  scale_color_manual(values = c("black", "grey"))+
  geom_jitter(aes(y=value, alpha=sameid), position = position_jitterdodge(jitter.width = 0.3, jitter.height = 0.05))+
  scale_x_discrete(labels = c("within", "between"))+
  scale_alpha_manual(values = c(0.5,0.5))+
  stat_summary(aes(y = value, group = sameid), 
             fun = mean, color = "red",
             position = position_dodge(.8)) +
  stat_summary(aes(y = value, group = sameid), 
    fun.min = function(x) mean(x) - sd(x), 
    fun.max = function(x) mean(x) + sd(x), 
    geom = "errorbar",
    color = "red",
    width = .3,
    position = position_dodge(.8)
  )+
  facet_wrap2(.~period, strip=strip, labeller = period_names, scales = "free")+
  guides(color="none", alpha="none")+
  ylab("BA overlap")+
  xlab("Individuals")+
  theme_classic()+
  theme(legend.position = "none", axis.title = element_text(size=20), axis.title.x = element_text(size = 20), axis.title.y=element_text(size=20), axis.text.y = element_text(size=14), axis.text.x = element_text(size=14))

within_between_all

ggsave(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/analysis/results/akde/overlap_all_fig.pdf", width = 5, height = 5)

library(patchwork)
### Composite figure area and patches
(within_between_all / cluster_plot) + plot_layout(axes = "collect_x") + plot_annotation(tag_levels = "A") &
  theme(
    plot.tag = element_text(size = 20)  # Customize tag size and appearance
  )

ggsave(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/analysis/figures/overlap_patches.pdf", width = 10, height = 9)
```
### Plot overlap by id
```{r}
ind_overlap <- overlap_all%>%
  filter(sameid=="yes")%>%
  ggplot(aes(y=id1, color=period)) +
  scale_color_manual(values=c("#756BB1", "#21918c","#F0E442"), name="Period", labels=c("Dry 2022-1", "Dry 2022-2","Wet 2023"))+
  geom_jitter(aes(x=value, alpha=sameid), position = position_jitterdodge(jitter.width = 0.3, jitter.height = 0.05))+
  scale_alpha_manual(values = c(0.3))+
  stat_summary(aes(x = value, group = sameid, color=period), 
             fun = mean,
             position = position_dodge(.8)) +
  stat_summary(aes(x = value, group = sameid,, color=period), 
    fun.min = function(x) mean(x) - sd(x), 
    fun.max = function(x) mean(x) + sd(x), 
    geom = "errorbar",
    width = .3,
    position = position_dodge(.8)
  )+
  guides(alpha="none")+
  ylab("Individuals")+
  xlab("BA overlap")+
  theme_classic()+
  theme(legend.position = "bottom", axis.title = element_text(size=20), axis.title.x = element_text(size = 20), axis.title.y=element_text(size=20), axis.text.y = element_text(size=14), axis.text.x = element_text(size=14))

ind_overlap 

ggsave(file="~/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/analysis/results/akde/overlap_byid.pdf", width = 10, height = 5)

```

###Test overlap
```{r}

library(rptR)
library(lme4)
library(glmmTMB)
library(DHARMa)

overlap_all$pairs <- paste(overlap_all$id1, overlap_all$id2, sep="_")
overlap_all$date <- paste(overlap_all$date1, overlap_all$date2, sep="_")

#convert zeros to positive values
epsilon <- 1e-6
overlap_all$value[which(overlap_all$value==0)] <- epsilon
overlap_all$value[which(overlap_all$value==1)] <- 1-epsilon

hist(overlap_all$value)

# model

# Logit transformation
overlap_all$logit_value <- log(overlap_all$value / (1 - overlap_all$value))
hist(overlap_all$logit_value)

# Fit the model using the transformed response
model <- lmer(logit_value ~ sameid* period + (1 | pairs), data = overlap_all)

summary(model)
car::Anova(model)
plot(model)

m_ove_beta <- glmmTMB(value ~ period*sameid+(1|pairs)+(1|date),
                       data = overlap_all,
                       family = beta_family(link = "probit"),
                        ziformula = ~1)

# summary of the model
summary(m_ove_beta)
car::Anova(m_ove_beta)

# Example: Marginal effect of `perioddry 2022-2` at the mean linear predictor
linear_predictor <- 0.2327  # Replace with fitted value for a specific condition
std_normal_pdf <- pnorm(linear_predictor)
estimate_no <- pnorm(0.2327 - 1.4815)  # Replace with the coefficient of interest
withinoverlap_dry2 <- pnorm(linear_predictor + 0.5737)
overlap_wet <- pnorm(linear_predictor + 0.1439)


# Check residuals
plot(residuals(m_ove_beta), main = "Residuals of Zero-Inflated Beta Model")
hist(residuals(m_ove_beta), main = "Histogram of Residuals")

# ACF plot of residuals
acf(residuals(m_ove_beta), main = "ACF of Residuals")

m_ove_beta_logit <- glmmTMB(value ~ period*sameid+(1|pairs)+(1|date),
                       data = overlap_all,
                       family = beta_family(link = "logit"),
                       ziformula = ~1)

summary(m_ove_beta_logit)

# Check residuals
plot(residuals(m_ove_beta_logit), main = "Residuals of Zero-Inflated Beta Model")
hist(residuals(m_ove_beta_logit), main = "Histogram of Residuals")

# ACF plot of residuals
acf(residuals(m_ove_beta_logit), main = "ACF of Residuals")

m_ove_beta_nozi <- glmmTMB(value ~ period*sameid+(1|pairs)+(1|date),
                            data = overlap_all,
                            family = beta_family(link = "logit"))

# Check residuals
plot(residuals(m_ove_beta_nozi), main = "Residuals of Zero-Inflated Beta Model")
hist(residuals(m_ove_beta_nozi), main = "Histogram of Residuals")

# ACF plot of residuals
acf(residuals(m_ove_beta_nozi), main = "ACF of Residuals")

summary(m_ove_beta_nozi)
plot(residuals(m_ove_beta_nozi))

AIC(m_ove_beta, m_ove_beta_logit,m_ove_beta_nozi)
```


### Plot areas for 2022 Feb 

```{r plotting areas in a map}
library(sf)
library(purrr)
library(stringr)

######################################################################
############  Plotting AKDE for idday on a map in 2022 ##############
######################################################################
# change UD list to sf object (mean contour only) and switch to lat long coords
# Safe conversion function
safe_as_sf <- purrr::safely(function(ud) {
  ctmm::as.sf(ud, level.UD = 0.95)
})

# Attempt to convert each UD object
safely_converted <- UDS_idday_filtered %>% 
  purrr::map(safe_as_sf)

# Extract only successful conversions
valid_sf_objects <- safely_converted %>%
  purrr::map("result") %>%
  purrr::compact() # remove NULLs (i.e., failed conversions)

UD_idday_sf <- valid_sf_objects %>%
  reduce(rbind) %>%
  mutate(id = rep(names(valid_sf_objects), each = 3), 
         ind = str_sub(id, 1, 8),
         day = str_sub(id, 12), 
         group = str_sub(id, 10, 10)) %>%
  filter(str_detect(name, "est")) %>%
  dplyr::select(id, ind, group, day, geometry) %>%
  st_transform(crs = "+proj=longlat +datum=WGS84")


# UD_idday_sf <- UDS_idday_filtered  %>% 
#   purrr::map(ctmm::as.sf, level.UD = 0.95) %>% 
#   reduce(rbind) %>% 
#   mutate(id = rep(names(UDS_idday_filtered), each = 3), ind =str_sub(id,1,8),
#          day = str_sub(id,12), group=str_sub(id,10,10)) %>% #year = as.numeric(str_sub(id,4,7)
#   filter(str_detect(name, "est")) %>% 
#   dplyr::select(id, ind, group, day, geometry) %>% #remove year from Odds code
#   st_transform(crs = "+proj=longlat +datum=WGS84")

# transform confidence intervals
CI_idday_sf <-  valid_sf_objects  %>% 
  purrr::map(ctmm::as.sf, level.UD = 0.95) %>% 
  reduce(rbind) %>% 
  mutate(id = rep(names(valid_sf_objects), each = 3), ind =str_sub(id,1,8),
         day = str_sub(id,12), group=str_sub(id,10,10)) %>% #year = as.numeric(str_sub(id,4,7)
  filter(!str_detect(name, "est")) %>% 
  dplyr::select(id,ind, group, day, geometry) %>% 
  st_transform(crs = "+proj=longlat +datum=WGS84")


# filter tele object
DATA_idday_sf <- tele.idday.feb[names(tele.idday.feb) %in% unique(UD_idday_sf$id)==TRUE] %>%
  purrr::map(ctmm::as.sf) %>% 
  reduce(rbind) %>% 
  mutate(id = identity,
         day = str_sub(id,12), ind =str_sub(id,1,8), group=str_sub(id,10,10)) %>% 
  dplyr::select(id,ind, group, day, geometry) %>% 
  st_transform(crs = "+proj=longlat +datum=WGS84")

# register stamen map
register_stadiamaps("") 

# create a bounding box
e <- make_bbox(location_long, location_lat, data = bats_feb, f = .70)


#plot by id_day
fld <-"/Users/ccalderon/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/analysis/results/akde/"
# i=2
for(i in 1:length(unique(CI_idday_sf$ind))){
  id <- unique(CI_idday_sf$ind)[i]
  pdf(file = paste0(fld,"akde_idday", id,".pdf"))
  plot <- get_stadiamap(e, zoom = 12, maptype = "stamen_terrain") %>% ggmap()+
  geom_sf(data = CI_idday_sf[CI_idday_sf$ind==id,], # can also use CI_sf[CI_sf$group=="group1",] if you want to do a specific group or individual only
          aes(fill=day, color=day, alpha = 0.02, size = 0.3),
          #color = "black",
          linetype = "dashed",
          inherit.aes = FALSE) +
          #alpha = 0.02,
          #size = 0.3) +
  geom_sf(data = UD_idday_sf[UD_idday_sf$ind==id,], # can also use UD_sf[UD_sf$group=="group1",] if you want to do a specific group or individual only
          aes(fill=day, color=day),
          inherit.aes = FALSE, 
          alpha = 0.3, 
          size = 0.3) +
  geom_sf(data = DATA_idday_sf[DATA_idday_sf$ind==id,], # can also use DATA_sf[DATA_sf$group=="group1",] if you want to do a specific group or individual only
          aes(color=day, alpha= 0.03),
          size = 0.5, 
          inherit.aes = FALSE) +
  ggspatial::annotation_scale(location = "bl", 
                              width_hint = 0.3,
                              height = unit(4,'pt'),
                              style = 'ticks') +
# coord_sf(xlim=c(-85.39,-85.35), ylim=c(10.495, 10.542)) + # can use this to trim the map to particular groups
  guides(color=guide_legend(override.aes=list(size = 3)))+
  #theme_bw(base_family = "ArcherPro Book") +
  theme(legend.position="bottom", 
        legend.title = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank())
print(plot)
while (!is.null(dev.list()))  dev.off()
}

#plot using laaply
# id_CI <- split(CI_idday_sf,CI_idday_sf$ind)
# id_UD <- split(UD_idday_sf,UD_idday_sf$ind)
# id_data <- split(DATA_idday_sf, DATA_idday_sf$ind)
# 
# lapply(1:length(id_CI), function(i){
#   indi <- unique(id_CI[[i]]$ind)
#   day <- id[[i]]$day
  plot <- get_stadiamap(e, zoom = 12, maptype = "stamen_terrain") %>% ggmap()+
   geom_sf(data = CI_idday_sf, # can also use CI_sf[CI_sf$group=="group1",] if you want to do a specific group or individual only
          aes(fill=day, color=day, alpha = 0.02, size = 0.3),
          #color = "black",
          linetype = "dashed",
          inherit.aes = FALSE) +
          #alpha = 0.02,
          #size = 0.3) +
  geom_sf(data = UD_idday_sf, # can also use UD_sf[UD_sf$group=="group1",] if you want to do a specific group or individual only
          aes(fill=day, color=day),
          inherit.aes = FALSE, 
          alpha = 0.3, 
          size = 0.3) +
  geom_sf(data = DATA_idday_sf, # can also use DATA_sf[DATA_sf$group=="group1",] if you want to do a specific group or individual only
          aes(color=day, alpha= 0.03),
          size = 0.5, 
          inherit.aes = FALSE) +
  ggspatial::annotation_scale(location = "bl", 
                              width_hint = 0.3,
                              height = unit(4,'pt'),
                              style = 'ticks') +
# coord_sf(xlim=c(-85.39,-85.35), ylim=c(10.495, 10.542)) + # can use this to trim the map to particular groups
  guides(color=guide_legend(override.aes=list(size = 3)))+
  #theme_bw(base_family = "ArcherPro Book") +
  theme(legend.position="bottom", 
        legend.title = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank())+
  facet_wrap(.~ind)
print(plot)

ggsave(plot, file="/Users/ccalderon/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/analysis/results/akde/akde_feb_all.pdf", width = 15, height = 20)
```

### Plot areas for 2022 March 

```{r plotting areas in a map}
# Attempt to convert each UD object
safely_converted_2022 <- UDS_2022_filtered %>% 
  purrr::map(safe_as_sf)

# Extract only successful conversions
valid_sf_objects_2022 <- safely_converted_2022 %>%
  purrr::map("result") %>%
  purrr::compact() # remove NULLs (i.e., failed conversions)

UD_2022_sf <- valid_sf_objects_2022 %>%
  reduce(rbind) %>%
  mutate(id = rep(names(valid_sf_objects_2022), each = 3), 
         ind = str_sub(id, end=-12),
         day = str_sub(id, -10)) %>%
  filter(str_detect(name, "est")) %>%
  dplyr::select(id, ind, day, geometry) %>%
  st_transform(crs = "+proj=longlat +datum=WGS84")


# UD_idday_sf <- UDS_idday_filtered  %>% 
#   purrr::map(ctmm::as.sf, level.UD = 0.95) %>% 
#   reduce(rbind) %>% 
#   mutate(id = rep(names(UDS_idday_filtered), each = 3), ind =str_sub(id,1,8),
#          day = str_sub(id,12), group=str_sub(id,10,10)) %>% #year = as.numeric(str_sub(id,4,7)
#   filter(str_detect(name, "est")) %>% 
#   dplyr::select(id, ind, group, day, geometry) %>% #remove year from Odds code
#   st_transform(crs = "+proj=longlat +datum=WGS84")

# transform confidence intervals
CI_2022_sf <-  valid_sf_objects_2022  %>% 
  purrr::map(ctmm::as.sf, level.UD = 0.95) %>% 
  reduce(rbind) %>% 
  mutate(id = rep(names(valid_sf_objects_2022), each = 3), ind = str_sub(id, end=-12),
         day = str_sub(id, -10)) %>% #year = as.numeric(str_sub(id,4,7)
  filter(!str_detect(name, "est")) %>% 
  dplyr::select(id,ind, day, geometry) %>% 
  st_transform(crs = "+proj=longlat +datum=WGS84")


# transform telemetry data into sf
DATA_2022_sf <- tele2022[names(tele2022) %in% unique(UD_2022_sf$id)==TRUE] %>%
  purrr::map(ctmm::as.sf) %>% 
  reduce(rbind) %>% 
  mutate(id = identity,
         ind = str_sub(id, end=-12),
         day = str_sub(id, -10)) %>% 
  dplyr::select(id,ind, day, geometry) %>% 
  st_transform(crs = "+proj=longlat +datum=WGS84")

# register stamen map
register_stadiamaps("") 

# create a bounding box
e <- make_bbox(location_long, location_lat, data = aftermarch, f = .70)

akde_march <- get_stadiamap(e, zoom = 11, maptype = "stamen_toner_lite") %>% ggmap()+
   geom_sf(data = CI_2022_sf, # can also use CI_sf[CI_sf$group=="group1",] if you want to do a specific group or individual only
          aes(fill=day, color=day, alpha = 0.02, size = 0.3),
          #color = "black",
          linetype = "dashed",
          inherit.aes = FALSE) +
          #alpha = 0.02,
          #size = 0.3) +
  geom_sf(data = UD_2022_sf, # can also use UD_sf[UD_sf$group=="group1",] if you want to do a specific group or individual only
          aes(fill=day, color=day),
          inherit.aes = FALSE, 
          alpha = 0.3, 
          size = 0.3) +
  geom_sf(data = DATA_2022_sf, # can also use DATA_sf[DATA_sf$group=="group1",] if you want to do a specific group or individual only
          aes(color=day, alpha= 0.03),
          size = 0.5, 
          inherit.aes = FALSE) +
  ggspatial::annotation_scale(location = "bl", 
                              width_hint = 0.3,
                              height = unit(4,'pt'),
                              style = 'ticks') +
# coord_sf(xlim=c(-85.39,-85.35), ylim=c(10.495, 10.542)) + # can use this to trim the map to particular groups
  guides(color=guide_legend(override.aes=list(size = 3)))+
  #theme_bw(base_family = "ArcherPro Book") +
  theme(legend.position="bottom", 
        legend.title = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank())+
  facet_wrap(.~ind)
print(akde_march)

ggsave(akde_march, file="/Users/ccalderon/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/analysis/results/akde/akde_march_all.pdf", width = 15, height = 20)

```
### Plot areas for 2023

```{r plotting areas in a map}

# Attempt to convert each UD object
safely_converted_2023 <- UDS_2023_filtered %>% 
  purrr::map(safe_as_sf)

# Extract only successful conversions
valid_sf_objects_2023 <- safely_converted_2023 %>%
  purrr::map("result") %>%
  purrr::compact() # remove NULLs (i.e., failed conversions)

UD_2023_sf <- valid_sf_objects_2023 %>%
  reduce(rbind) %>%
  mutate(id = rep(names(valid_sf_objects_2023), each = 3), 
         ind = str_sub(id, end=-12),
         day = str_sub(id, -10)) %>%
  filter(str_detect(name, "est")) %>%
  dplyr::select(id, ind, day, geometry) %>%
  st_transform(crs = "+proj=longlat +datum=WGS84")


# UD_idday_sf <- UDS_idday_filtered  %>% 
#   purrr::map(ctmm::as.sf, level.UD = 0.95) %>% 
#   reduce(rbind) %>% 
#   mutate(id = rep(names(UDS_idday_filtered), each = 3), ind =str_sub(id,1,8),
#          day = str_sub(id,12), group=str_sub(id,10,10)) %>% #year = as.numeric(str_sub(id,4,7)
#   filter(str_detect(name, "est")) %>% 
#   dplyr::select(id, ind, group, day, geometry) %>% #remove year from Odds code
#   st_transform(crs = "+proj=longlat +datum=WGS84")

# transform confidence intervals
CI_2023_sf <-  valid_sf_objects_2023  %>% 
  purrr::map(ctmm::as.sf, level.UD = 0.95) %>% 
  reduce(rbind) %>% 
  mutate(id = rep(names(valid_sf_objects_2023), each = 3), ind = str_sub(id, end=-12),
         day = str_sub(id, -10)) %>% #year = as.numeric(str_sub(id,4,7)
  filter(!str_detect(name, "est")) %>% 
  dplyr::select(id,ind, day, geometry) %>% 
  st_transform(crs = "+proj=longlat +datum=WGS84")


# transform telemetry data into sf
DATA_2023_sf <- tele2023[names(tele2023) %in% unique(UD_2023_sf$id)==TRUE] %>%
  purrr::map(ctmm::as.sf) %>% 
  reduce(rbind) %>% 
  mutate(id = identity,
         ind = str_sub(id, end=-12),
         day = str_sub(id, -10)) %>% 
  dplyr::select(id,ind, day, geometry) %>% 
  st_transform(crs = "+proj=longlat +datum=WGS84")

# register stamen map
register_stadiamaps("") 

# create a bounding box
e <- make_bbox(location_long, location_lat, data = aftermarch, f = .70)

akde_2023 <- get_stadiamap(e, zoom = 11, maptype = "stamen_toner_lite") %>% ggmap()+
   geom_sf(data = CI_2023_sf, # can also use CI_sf[CI_sf$group=="group1",] if you want to do a specific group or individual only
          aes(fill=day, color=day, alpha = 0.02, size = 0.3),
          #color = "black",
          linetype = "dashed",
          inherit.aes = FALSE) +
          #alpha = 0.02,
          #size = 0.3) +
  geom_sf(data = UD_2023_sf, # can also use UD_sf[UD_sf$group=="group1",] if you want to do a specific group or individual only
          aes(fill=day, color=day),
          inherit.aes = FALSE, 
          alpha = 0.3, 
          size = 0.3) +
  geom_sf(data = DATA_2023_sf, # can also use DATA_sf[DATA_sf$group=="group1",] if you want to do a specific group or individual only
          aes(color=day, alpha= 0.03),
          size = 0.5, 
          inherit.aes = FALSE) +
  ggspatial::annotation_scale(location = "bl", 
                              width_hint = 0.3,
                              height = unit(4,'pt'),
                              style = 'ticks') +
# coord_sf(xlim=c(-85.39,-85.35), ylim=c(10.495, 10.542)) + # can use this to trim the map to particular groups
  guides(color=guide_legend(override.aes=list(size = 3)))+
  #theme_bw(base_family = "ArcherPro Book") +
  theme(legend.position="bottom", 
        legend.title = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank())+
  facet_wrap(.~ind)
print(akde_2023)

ggsave(akde_2023, file="/Users/ccalderon/ownCloud/PhDLife/P.hastatus/Thesis/Paper3/analysis/results/akde/akde_2023_all.pdf", width = 15, height = 20)

```



